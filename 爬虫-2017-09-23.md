目的：从各个门户网站爬重要的数据，提取到本地，进行分析加工
python做爬虫的几个模块：
requests
beautifulSoul4

爬炼狱庭园为例
```
import requests

from bs4 import BeautifulSoup

response=requests.get('http://www.rengoku-teien.com/mp3/pop.html')
response.encoding = 'utf8'
print(response.text)
```

request.get参数：
url
params  传一个字典给url,作为get的参数
stream=True   当需要下载文件时，开启这个参数，循环接收内容

response的属性：
response.status_code
response.cookies.get_dict()
response.content   //字节形式的请求体
response.text   //字符串形式的请求体，如果乱码，解决方法是在之前更改response.encoding，或者直接使用content转

response.iter_content   当需要下载文件时，get参数开启stream的时候，这边会循环接受

response上传下载文件
```

```

